{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b7afc81",
   "metadata": {},
   "source": [
    "## STEP 01: DIVISION of BLOCKS (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea1d666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'large_text_file.txt' is your 10MB text file.\n",
    "filename = 'C:/Users/sohar/OneDrive/Desktop/Map_reduce/rhyme.txt'\n",
    "\n",
    "# Determine the total number of lines to approximate splitting.\n",
    "with open(filename, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "total_lines = len(lines)\n",
    "lines_per_block = total_lines // 4\n",
    "\n",
    "# Split the file into 4 parts and write each part to a separate 'node' file.\n",
    "for i in range(4):\n",
    "    with open(f'node_{i+1}.txt', 'w') as file:\n",
    "        for line in lines[i*lines_per_block : (i+1)*lines_per_block]:\n",
    "            file.write(line)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04bb55",
   "metadata": {},
   "source": [
    "## STEP 02: RECORD READER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e783887e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records from node_1.txt:\n",
      "(1, 'ï»¿')\n",
      "(2, 'Sing a Song of Sixpence.')\n",
      "(3, '')\n",
      "(4, 'A brand new sixpence fresh from the Mint!  How it sparkled and glittered')\n",
      "(5, 'in the dancing sunlight!  Such a treasure for a small girl to possess!')\n",
      "\n",
      "---\n",
      "\n",
      "First 5 records from node_2.txt:\n",
      "(1, '\"Oh dear, what can the matter be?')\n",
      "(2, 'Dear, dear, what can the matter be?')\n",
      "(3, 'Oh dear, what can the matter be?')\n",
      "(4, 'Nellieâ€™s so long making tea!')\n",
      "(5, 'She promised to give me some bread and some honey,')\n",
      "\n",
      "---\n",
      "\n",
      "First 5 records from node_3.txt:\n",
      "(1, '')\n",
      "(2, 'She was a strange child, and led a lonely life, shut up in the almost')\n",
      "(3, 'deserted castle with no one but her miserly old grandfather and old')\n",
      "(4, 'Nanny for company.  It was no wonder that she grew up with curious')\n",
      "(5, 'unchildlike fancies, which were yet not altogether unchildlike.  Her')\n",
      "\n",
      "---\n",
      "\n",
      "First 5 records from node_4.txt:\n",
      "(1, 'though it were lined with cotton wool.  Elsie felt cold and stiff, and')\n",
      "(2, 'her limbs ached--she felt she could not stay much longer in her snowy')\n",
      "(3, 'bed.')\n",
      "(4, '')\n",
      "(5, '\"Fly home, Robin, and tell granâ€™fer,\" she repeated, and Robin flew away.')\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_records_from_node(node_filename):\n",
    "    \"\"\"\n",
    "    Reads records from a given node file and returns a list of (key, value) pairs,\n",
    "    where key is the line number and value is the text of the line.\n",
    "    \"\"\"\n",
    "    with open(node_filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Generate (line_number, line_text) pairs\n",
    "    records = [(i+1, line.strip()) for i, line in enumerate(lines)]\n",
    "    return records\n",
    "\n",
    "# Process for all 4 nodes\n",
    "for i in range(4):\n",
    "    node_filename = f'node_{i+1}.txt'\n",
    "    records = read_records_from_node(node_filename)\n",
    "    \n",
    "    # Here you can process records further as needed\n",
    "    # For demonstration, we'll just print the first 5 records of each node\n",
    "    print(f\"First 5 records from {node_filename}:\")\n",
    "    for record in records[:5]:\n",
    "        print(record)\n",
    "    print(\"\\n---\\n\")  # Just to separate output for clarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e11fd3d",
   "metadata": {},
   "source": [
    "## STEP 03:  MAPPER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea5fd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 (word, frequency) pairs from node 1:\n",
      "ï»¿: 1\n",
      "sing: 1\n",
      "a: 1\n",
      "song: 1\n",
      "of: 1\n",
      "sixpence.: 1\n",
      "a: 1\n",
      "brand: 1\n",
      "new: 1\n",
      "sixpence: 1\n",
      "First 10 (word, frequency) pairs from node 2:\n",
      "\"oh: 1\n",
      "dear,: 1\n",
      "what: 1\n",
      "can: 1\n",
      "the: 1\n",
      "matter: 1\n",
      "be?: 1\n",
      "dear,: 2\n",
      "what: 1\n",
      "can: 1\n",
      "First 10 (word, frequency) pairs from node 3:\n",
      "she: 1\n",
      "was: 1\n",
      "a: 2\n",
      "strange: 1\n",
      "child,: 1\n",
      "and: 1\n",
      "led: 1\n",
      "lonely: 1\n",
      "life,: 1\n",
      "shut: 1\n",
      "First 10 (word, frequency) pairs from node 4:\n",
      "though: 1\n",
      "it: 1\n",
      "were: 1\n",
      "lined: 1\n",
      "with: 1\n",
      "cotton: 1\n",
      "wool.: 1\n",
      "elsie: 1\n",
      "felt: 1\n",
      "cold: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def mapper(records):\n",
    "    \"\"\"\n",
    "    Processes a list of records from a node, ignoring the keys and considering only the values (sentences).\n",
    "    For each word in a sentence, it calculates the frequency of that word in that sentence.\n",
    "    \n",
    "    :param records: List of (key, value) pairs where key is the line number and value is the sentence.\n",
    "    :return: A list of (word, frequency) pairs for words in the sentences.\n",
    "    \"\"\"\n",
    "    word_frequencies = []\n",
    "    for _, sentence in records:\n",
    "        # Tokenize the sentence into words, assuming words are separated by spaces.\n",
    "        # Convert to lowercase to ensure case-insensitive counting.\n",
    "        words = sentence.lower().split()\n",
    "        # Count the frequency of each word in the sentence\n",
    "        frequencies = Counter(words)\n",
    "        # Extend the word_frequencies list with (word, frequency) pairs from this sentence\n",
    "        word_frequencies.extend(frequencies.items())\n",
    "    return word_frequencies\n",
    "\n",
    "# Assuming `read_records_from_node` has already been defined and used to read records from each node\n",
    "# Example usage for node 1\n",
    "node_1_records = read_records_from_node('node_1.txt')\n",
    "node_1_word_frequencies = mapper(node_1_records)\n",
    "node_2_records = read_records_from_node('node_2.txt')\n",
    "node_2_word_frequencies = mapper(node_2_records)\n",
    "node_3_records = read_records_from_node('node_3.txt')\n",
    "node_3_word_frequencies = mapper(node_3_records)\n",
    "node_4_records = read_records_from_node('node_4.txt')\n",
    "node_4_word_frequencies = mapper(node_4_records)\n",
    "\n",
    "# For demonstration, print the first 10 (word, frequency) pairs from node 1\n",
    "print(\"First 10 (word, frequency) pairs from node 1:\")\n",
    "for word, freq in node_1_word_frequencies[:10]:\n",
    "    print(f\"{word}: {freq}\")\n",
    "    \n",
    "print(\"First 10 (word, frequency) pairs from node 2:\")\n",
    "for word, freq in node_2_word_frequencies[:10]:\n",
    "    print(f\"{word}: {freq}\")\n",
    "    \n",
    "print(\"First 10 (word, frequency) pairs from node 3:\")\n",
    "for word, freq in node_3_word_frequencies[:10]:\n",
    "    print(f\"{word}: {freq}\")\n",
    "    \n",
    "print(\"First 10 (word, frequency) pairs from node 4:\")\n",
    "for word, freq in node_4_word_frequencies[:10]:\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea2dc14",
   "metadata": {},
   "source": [
    "## STEP 04:  SHUFFLE SORTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "290bcbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming mapper and read_records_from_node are already defined\n",
    "# Aggregate outputs from all 4 mappers\n",
    "all_mapper_outputs = []\n",
    "for i in range(4):\n",
    "    node_records = read_records_from_node(f'node_{i+1}.txt')\n",
    "    mapper_output = mapper(node_records)\n",
    "    all_mapper_outputs.extend(mapper_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cd5865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿: [1]\n",
      "sing: [1, 1, 1, 1]\n",
      "a: [1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1]\n",
      "song: [1, 1]\n",
      "of: [1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "sixpence.: [1, 1, 1, 1]\n",
      "brand: [1]\n",
      "new: [1, 1, 1, 1, 2, 1]\n",
      "sixpence: [1, 1, 1]\n",
      "fresh: [1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def shuffle_and_sort(mapper_outputs):\n",
    "    \"\"\"\n",
    "    Aggregates word counts from all mapper outputs, effectively performing the shuffle operation.\n",
    "    This function groups counts for each unique word across all mapper outputs.\n",
    "    \n",
    "    :param mapper_outputs: Combined list of (word, frequency) pairs from all mappers.\n",
    "    :return: Dictionary where the key is the word and the value is a list of counts.\n",
    "    \"\"\"\n",
    "    shuffle_sort_output = defaultdict(list)\n",
    "    for word, frequency in mapper_outputs:\n",
    "        shuffle_sort_output[word].append(frequency)\n",
    "    return shuffle_sort_output\n",
    "\n",
    "# Perform shuffle and sort on aggregated mapper outputs\n",
    "node_5_output = shuffle_and_sort(all_mapper_outputs)\n",
    "\n",
    "# Display the output for demonstration purposes\n",
    "for word, frequencies in list(node_5_output.items())[:10]:  # Limiting output for brevity\n",
    "    print(f\"{word}: {frequencies}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49308a32",
   "metadata": {},
   "source": [
    "## STEP 05: REDUCER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3835596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿: 1\n",
      "sing: 4\n",
      "a: 141\n",
      "song: 2\n",
      "of: 83\n",
      "sixpence.: 4\n",
      "brand: 1\n",
      "new: 7\n",
      "sixpence: 3\n",
      "fresh: 3\n"
     ]
    }
   ],
   "source": [
    "def reducer(shuffle_sort_output):\n",
    "    \"\"\"\n",
    "    Aggregates the counts for each word by summing up the frequencies.\n",
    "    \n",
    "    :param shuffle_sort_output: A dictionary where the key is the word and the value is a list of counts.\n",
    "    :return: A dictionary with the word as the key and the total count as the value.\n",
    "    \"\"\"\n",
    "    reduced_output = {}\n",
    "    for word, frequencies in shuffle_sort_output.items():\n",
    "        # Sum up all the frequencies for the word to get the total count\n",
    "        total_count = sum(frequencies)\n",
    "        reduced_output[word] = total_count\n",
    "    return reduced_output\n",
    "\n",
    "# Assuming node_5_output is the output from the shuffle and sort step\n",
    "final_output = reducer(node_5_output)\n",
    "\n",
    "# Display some of the reduced output for demonstration purposes\n",
    "for word, total_count in list(final_output.items())[:10]:  # Limiting output for brevity\n",
    "    print(f\"{word}: {total_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb5e870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
